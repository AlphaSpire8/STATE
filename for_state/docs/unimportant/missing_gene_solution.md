# STæ¨¡å‹ç¼ºå¤±åŸºå› é—®é¢˜è§£å†³æ–¹æ¡ˆ

## ğŸ“‹ é—®é¢˜æ‘˜è¦

### å½“å‰çŠ¶å†µ
- **æµ‹è¯•æ•°æ®é›†**: FrangiehIzar2021 (CRISPR-cas9æ‰°åŠ¨)
- **æ¨¡å‹**: ST-Tahoe (é¢„è®­ç»ƒåœ¨2000ä¸ªé«˜å˜åŸºå› ä¸Š)
- **æ ¸å¿ƒé—®é¢˜**: æµ‹è¯•æ•°æ®ç¼ºå¤±éƒ¨åˆ†è®­ç»ƒé›†åŸºå› ï¼Œç”¨0è¡¥å…¨æ•ˆæœå·®
- **å®éªŒç»“æœ**: run23æ˜¾ç¤ºç›´æ¥æ¨ç†å¯ä»¥è¿è¡Œï¼Œä½†æ€§èƒ½æœªçŸ¥

### æ ¹æœ¬åŸå› åˆ†æ
1. **æ•°æ®åˆ†å¸ƒä¸åŒ¹é…**: æµ‹è¯•æ•°æ®çš„åŸºå› é›†ä¸è®­ç»ƒæ•°æ®(`var_dims.pkl`)ä¸å®Œå…¨ä¸€è‡´
2. **ä¿¡æ¯ä¸¢å¤±**: é›¶è¡¥å…¨å¯¼è‡´å¤§é‡è™šå‡é›¶å€¼ï¼Œç ´åäº†æ•°æ®çš„çœŸå®åˆ†å¸ƒ
3. **æ¨¡å‹ä¾èµ–**: STæ¨¡å‹æ¶æ„ä¾èµ–å›ºå®šç»´åº¦çš„è¾“å…¥ (2000ç»´é«˜å˜åŸºå› )

## ğŸ—ï¸ STæ¨¡å‹æ¶æ„å…³é”®ç‚¹

### æ¨¡å‹è¾“å…¥æµç¨‹
```mermaid
graph LR
    A[åŸå§‹è¡¨è¾¾çŸ©é˜µ] --> B[ç­›é€‰é«˜å˜åŸºå›  var_dims.pkl]
    B --> C[Basal Encoder<br/>è¾“å…¥ç»´åº¦å›ºå®š]
    C --> D[Transformer Backbone]
    D --> E[Project Out<br/>è¾“å‡ºç»´åº¦å›ºå®š]
    E --> F[é¢„æµ‹æ‰°åŠ¨æ•ˆåº”]
```

### å…³é”®ç»„ä»¶ä¾èµ–å…³ç³»

1. **Basal Encoder** ([`state_transition.py:320-330`](../src/state/tx/models/state_transition.py:320))
   - è¾“å…¥ç»´åº¦: `input_dim` (å¿…é¡»åŒ¹é… `var_dims.pkl` çš„åŸºå› æ•°)
   - åŠŸèƒ½: å°†åŸºå› è¡¨è¾¾ç¼–ç åˆ°éšç©ºé—´
   - æ˜¯å¦å¯è°ƒæ•´: **å¯ä»¥ï¼Œä½†éœ€è¦é‡æ–°è®­ç»ƒæˆ–é€‚é…**

2. **Perturbation Encoder** ([`state_transition.py:310-317`](../src/state/tx/models/state_transition.py:310))
   - è¾“å…¥ç»´åº¦: `pert_dim` (æ‰°åŠ¨ç¼–ç ç»´åº¦)
   - ä¸åŸºå› ç»´åº¦è§£è€¦ï¼Œä¸å—åŸºå› ç¼ºå¤±å½±å“

3. **Transformer Backbone** ([`state_transition.py:332-335`](../src/state/tx/models/state_transition.py:332))
   - å·¥ä½œåœ¨éšç©ºé—´ï¼Œä¸ç›´æ¥ä¾èµ–åŸºå› ç»´åº¦
   - ä½ç½®ç¼–ç : `n_positions = cell_sentence_len + extra_tokens`

4. **Output Projection** ([`state_transition.py:348-355`](../src/state/tx/models/state_transition.py:348))
   - è¾“å‡ºç»´åº¦: `output_dim` (å¿…é¡»åŒ¹é…ç›®æ ‡åŸºå› æ•°)

## ğŸ¯ å››ç§è§£å†³æ–¹æ¡ˆè¯¦ç»†è¯„ä¼°

---

## æ–¹æ¡ˆ1: åªä½¿ç”¨å…±åŒåŸºå› 

### åŸç†
ä¿®æ”¹é¢„å¤„ç†è„šæœ¬ï¼Œåªä¿ç•™æµ‹è¯•æ•°æ®å’Œ`var_dims.pkl`ä¸­éƒ½å­˜åœ¨çš„åŸºå› ï¼Œè°ƒæ•´æ¨¡å‹çš„è¾“å…¥è¾“å‡ºç»´åº¦ã€‚

### ä¼˜ç‚¹
âœ… å®ç°ç®€å•ï¼Œä¿®æ”¹é‡å°  
âœ… æ•°æ®çœŸå®ï¼Œæ— éœ€è¡¥å…¨  
âœ… é¿å…é›¶å€¼å¸¦æ¥çš„åˆ†å¸ƒåç§»

### ç¼ºç‚¹
âŒ **æ¨¡å‹ç»´åº¦ä¸åŒ¹é…**: Basal EncoderæœŸæœ›å›ºå®šè¾“å…¥ç»´åº¦  
âŒ **ä¿¡æ¯æŸå¤±**: å¯èƒ½ä¸¢å¤±å¤§é‡è®­ç»ƒé›†ç‰¹å¾  
âŒ **éœ€è¦ä¿®æ”¹æ¨¡å‹åŠ è½½é€»è¾‘**: ä¸æ˜¯å¼€ç®±å³ç”¨

### å®æ–½æ­¥éª¤

#### 1.1 ä¿®æ”¹é¢„å¤„ç†è„šæœ¬
åˆ›å»ºæ–°ç‰ˆæœ¬ `screen_hvgs_intersection.py`:

```python
def screen_hvgs_intersection(data_in, data_out, model_dir):
    """
    åªä½¿ç”¨æµ‹è¯•é›†å’Œæ¨¡å‹å…±åŒæ‹¥æœ‰çš„åŸºå› 
    """
    # 1. åŠ è½½æ•°æ®å’Œæ¨¡å‹åŸºå› åˆ—è¡¨
    adata = ad.read_h5ad(data_in)
    hvg_names = pickle.load(open(f'{model_dir}/var_dims.pkl', 'rb'))['gene_names']
    
    # 2. è®¡ç®—äº¤é›†åŸºå› 
    valid_genes = list(set(hvg_names) & set(adata.var_names))
    print(f"äº¤é›†åŸºå› æ•°: {len(valid_genes)}/{len(hvg_names)}")
    
    # 3. å­é›†æ•°æ®
    adata_subset = adata[:, valid_genes].copy()
    
    # 4. ä¿å­˜åŸºå› ç´¢å¼•æ˜ å°„ï¼ˆç”¨äºæ¨¡å‹è°ƒæ•´ï¼‰
    gene_to_idx = {g: i for i, g in enumerate(hvg_names)}
    valid_indices = [gene_to_idx[g] for g in valid_genes]
    
    # ä¿å­˜æ˜ å°„ä¿¡æ¯
    mapping = {
        'valid_genes': valid_genes,
        'valid_indices': valid_indices,
        'original_gene_count': len(hvg_names),
        'intersection_gene_count': len(valid_genes)
    }
    with open(data_out.replace('.h5ad', '_gene_mapping.pkl'), 'wb') as f:
        pickle.dump(mapping, f)
    
    adata_subset.write_h5ad(data_out)
```

#### 1.2 è°ƒæ•´æ¨¡å‹è¾“å…¥å±‚
éœ€è¦åˆ›å»ºä¸€ä¸ªé€‚é…å™¨æ¥å¤„ç†ç»´åº¦ä¸åŒ¹é…:

```python
class GeneDimensionAdapter(nn.Module):
    """
    å°†ç¼©å‡ç»´åº¦çš„è¾“å…¥æ˜ å°„åˆ°æ¨¡å‹æœŸæœ›çš„ç»´åº¦
    """
    def __init__(self, valid_indices, full_dim):
        super().__init__()
        self.valid_indices = torch.tensor(valid_indices, dtype=torch.long)
        self.full_dim = full_dim
        
    def forward(self, x_subset):
        # x_subset: (batch, subset_dim)
        batch_size = x_subset.size(0)
        x_full = torch.zeros(batch_size, self.full_dim, device=x_subset.device)
        x_full[:, self.valid_indices] = x_subset
        return x_full
```

### é¢„æœŸæ•ˆæœ
- **å‡†ç¡®æ€§**: ğŸŸ¡ ä¸­ç­‰ (ä¿¡æ¯æŸå¤±å¯èƒ½å½±å“é¢„æµ‹)
- **æ³›åŒ–æ€§**: ğŸ”´ å·® (ä¾èµ–åŸºå› äº¤é›†ï¼Œä¸åŒæ•°æ®é›†å·®å¼‚å¤§)
- **å®æ–½éš¾åº¦**: ğŸŸ¢ ç®€å•
- **æ¨èæŒ‡æ•°**: â­â­ (ä»…ä½œä¸ºbaselineå¯¹æ¯”)

---

## æ–¹æ¡ˆ2: å¾®è°ƒæ¨¡å‹ (LoRA)

### åŸç†
ä½¿ç”¨LoRAå¯¹æ¨¡å‹çš„Basal Encoderè¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶é€‚åº”æ–°æ•°æ®é›†çš„åŸºå› åˆ†å¸ƒã€‚

### ä¼˜ç‚¹
âœ… ä¿ç•™é¢„è®­ç»ƒçŸ¥è¯†  
âœ… å‚æ•°é«˜æ•ˆ (åªè®­ç»ƒ1-2%å‚æ•°)  
âœ… å¯ä»¥é€‚åº”æ–°çš„åŸºå› åˆ†å¸ƒ  
âœ… å·²æœ‰æˆç†Ÿè„šæœ¬ ([`finetune_v2.py`](../for_state/scripts/finetune_v2.py))

### ç¼ºç‚¹
âŒ éœ€è¦æ ‡æ³¨çš„å¾®è°ƒæ•°æ® (æ‰°åŠ¨-è¡¨è¾¾å¯¹)  
âŒ ä»æœªè§£å†³è¾“å…¥ç»´åº¦é—®é¢˜  
âŒ å¾®è°ƒå¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆï¼ˆå¦‚æœæ•°æ®å°‘ï¼‰

### å®æ–½æ­¥éª¤

#### 2.1 å‡†å¤‡å¾®è°ƒæ•°æ®
éœ€è¦æµ‹è¯•æ•°æ®é›†ä¸­åŒ…å«ï¼š
- æ§åˆ¶ç»„ç»†èƒ (`Control` æˆ– `DMSO`)
- æ‰°åŠ¨ç»„ç»†èƒ (å¸¦æ‰°åŠ¨æ ‡ç­¾)

#### 2.2 ä½¿ç”¨é›¶è¡¥å…¨ + LoRAå¾®è°ƒ

```bash
# æ­¥éª¤1: æ•°æ®é¢„å¤„ç†ï¼ˆä½¿ç”¨é›¶è¡¥å…¨ï¼‰
python screen_hvgs.py \
  --data_in FrangiehIzar2021_RNA.h5ad \
  --data_out FI_prep.h5ad \
  --model_dir /path/to/ST-Tahoe \
  --fill_missing True

# æ­¥éª¤2: LoRAå¾®è°ƒ
export CUDA_VISIBLE_DEVICES=3
python finetune_v2.py \
  --model_dir /path/to/ST-Tahoe \
  --checkpoint /path/to/ST-Tahoe/final_from_preprint.ckpt \
  --adata FI_prep.h5ad \
  --pert_col perturbation_2 \
  --output_lora ./lora_FI.pth \
  --epochs 10 \
  --batch_size 128 \
  --lr 5e-4 \
  --lora_rank 16 \
  --use_delta_loss \
  --batch_col plate \
  --control_label "Control"
```

#### 2.3 ä½¿ç”¨å¾®è°ƒæ¨¡å‹æ¨ç†

ä¿®æ”¹æ¨ç†è„šæœ¬åŠ è½½LoRAæƒé‡ï¼ˆéœ€è¦å®ç°`infer_with_lora.py`ï¼‰

### é¢„æœŸæ•ˆæœ
- **å‡†ç¡®æ€§**: ğŸŸ¢ é«˜ (å¦‚æœæœ‰è¶³å¤Ÿå¾®è°ƒæ•°æ®)
- **æ³›åŒ–æ€§**: ğŸŸ¡ ä¸­ç­‰ (ä»…é€‚é…ç‰¹å®šæ•°æ®é›†)
- **å®æ–½éš¾åº¦**: ğŸŸ¢ ç®€å• (å·²æœ‰è„šæœ¬)
- **æ¨èæŒ‡æ•°**: â­â­â­â­ (æœ‰æ ‡æ³¨æ•°æ®æ—¶çš„é¦–é€‰)

---

## æ–¹æ¡ˆ3: ä½¿ç”¨Embeddingæ˜ å°„

### åŸç†
å°†ç¼ºå¤±åŸºå› çš„è¡¨è¾¾çŸ©é˜µæŠ•å½±åˆ°ä½ç»´embeddingç©ºé—´ï¼Œç„¶åè®­ç»ƒä¸€ä¸ªæ˜ å°„å‡½æ•°å°†å…¶è½¬æ¢ä¸ºæ¨¡å‹æœŸæœ›çš„ç»´åº¦ã€‚

### ä¼˜ç‚¹
âœ… çµæ´»ï¼Œå¯ä»¥å¤„ç†ä»»æ„åŸºå› é›†  
âœ… å¯ä»¥å­¦ä¹ æ•°æ®é›†ç‰¹å®šçš„åŸºå› å…³ç³»  
âœ… ä¸éœ€è¦ä¿®æ”¹åŸå§‹æ¨¡å‹

### ç¼ºç‚¹
âŒ **å®æ–½å¤æ‚**: éœ€è¦é¢å¤–è®­ç»ƒæ˜ å°„æ¨¡å‹  
âŒ **æ•°æ®éœ€æ±‚**: éœ€è¦å¤§é‡æ— æ ‡ç­¾æ•°æ®è®­ç»ƒæ˜ å°„  
âŒ **æ€§èƒ½ä¸ç¡®å®š**: å¯èƒ½å¼•å…¥é¢å¤–è¯¯å·®

### å®æ–½æ­¥éª¤

#### 3.1 è®­ç»ƒåŸºå› åµŒå…¥
ä½¿ç”¨è‡ªç¼–ç å™¨å­¦ä¹ åŸºå› é—´å…³ç³»ï¼š

```python
class GeneAutoencoder(nn.Module):
    def __init__(self, input_genes, target_genes, latent_dim=512):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(len(input_genes), latent_dim),
            nn.BatchNorm1d(latent_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(latent_dim, latent_dim // 2)
        )
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim // 2, latent_dim),
            nn.BatchNorm1d(latent_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(latent_dim, len(target_genes))
        )
    
    def forward(self, x):
        latent = self.encoder(x)
        reconstructed = self.decoder(latent)
        return reconstructed
```

#### 3.2 è®­ç»ƒæ˜ å°„æ¨¡å‹

```python
def train_gene_mapper(adata_source, adata_target, epochs=100):
    """
    è®­ç»ƒä»ç›®æ ‡åŸºå› é›†åˆ°æºåŸºå› é›†çš„æ˜ å°„
    
    Args:
        adata_source: ä¸æ¨¡å‹åŒ¹é…çš„æ•°æ®ï¼ˆå¯ç”¨æ§åˆ¶ç»„æ•°æ®ï¼‰
        adata_target: æµ‹è¯•æ•°æ®
    """
    # æ‰¾åˆ°å…±åŒåŸºå› ï¼Œä½œä¸ºç›‘ç£ä¿¡å·
    common_genes = list(set(adata_source.var_names) & 
                       set(adata_target.var_names))
    
    # è®­ç»ƒæ•°æ®ï¼šç”¨å…±åŒåŸºå› ä½œä¸ºé‡å»ºç›®æ ‡
    mapper = GeneAutoencoder(
        input_genes=adata_target.var_names,
        target_genes=adata_source.var_names
    )
    
    # è®­ç»ƒ...
    return mapper
```

#### 3.3 åº”ç”¨æ˜ å°„è¿›è¡Œæ¨ç†

```python
# 1. åŠ è½½æ˜ å°„æ¨¡å‹
gene_mapper = torch.load('gene_mapper.pth')

# 2. æ˜ å°„æµ‹è¯•æ•°æ®
X_test_original = adata_test.X  # (n_cells, n_genes_test)
X_test_mapped = gene_mapper(torch.from_numpy(X_test_original))  # (n_cells, 2000)

# 3. ä½¿ç”¨æ˜ å°„åçš„æ•°æ®è¿›è¡ŒSTæ¨ç†
# ...
```

### é¢„æœŸæ•ˆæœ
- **å‡†ç¡®æ€§**: ğŸŸ¡ ä¸­ç­‰ (å–å†³äºæ˜ å°„è´¨é‡)
- **æ³›åŒ–æ€§**: ğŸŸ¢ é«˜ (å¯é€‚é…ä¸åŒåŸºå› é›†)
- **å®æ–½éš¾åº¦**: ğŸ”´ å¤æ‚
- **æ¨èæŒ‡æ•°**: â­â­ (éœ€è¦å¤§é‡å·¥ç¨‹å·¥ä½œ)

---

## æ–¹æ¡ˆ4: ä¿®æ”¹é¢„å¤„ç†è„šæœ¬ (å¢å¼ºé›¶è¡¥å…¨)

### åŸç†
æ”¹è¿›é›¶è¡¥å…¨ç­–ç•¥ï¼Œä½¿ç”¨ç»Ÿè®¡æ–¹æ³•ä¼°è®¡ç¼ºå¤±åŸºå› çš„è¡¨è¾¾å€¼ï¼Œè€Œéç®€å•å¡«0ã€‚

### ä¼˜ç‚¹
âœ… å®æ–½ç®€å•  
âœ… ä¿æŒæ¨¡å‹ä¸å˜  
âœ… å¯ä»¥ç»“åˆç”Ÿç‰©å­¦å…ˆéªŒçŸ¥è¯†

### ç¼ºç‚¹
âŒ ä¼°è®¡å¯èƒ½ä¸å‡†ç¡®  
âŒ å¼•å…¥äººå·¥æ•°æ®ï¼Œå¯èƒ½å¸¦æ¥bias

### å®æ–½æ­¥éª¤

#### 4.1 æ”¹è¿›çš„è¡¥å…¨ç­–ç•¥

```python
def screen_hvgs_smart_impute(data_in, data_out, model_dir):
    """
    ä½¿ç”¨æ™ºèƒ½è¡¥å…¨ç­–ç•¥å¡«å……ç¼ºå¤±åŸºå› 
    """
    # 1. åŠ è½½æ•°æ®
    adata = ad.read_h5ad(data_in)
    hvg_names = pickle.load(open(f'{model_dir}/var_dims.pkl', 'rb'))['gene_names']
    
    # 2. è¯†åˆ«ç¼ºå¤±åŸºå› 
    valid_genes = [g for g in hvg_names if g in adata.var_names]
    missing_genes = [g for g in hvg_names if g not in adata.var_names]
    
    print(f"æœ‰æ•ˆåŸºå› : {len(valid_genes)}, ç¼ºå¤±åŸºå› : {len(missing_genes)}")
    
    # 3. åˆ›å»ºå®Œæ•´çŸ©é˜µ
    n_cells = adata.n_obs
    X_complete = np.zeros((n_cells, len(hvg_names)), dtype=np.float32)
    
    # 4. å¡«å……å·²æœ‰åŸºå› 
    gene_to_idx = {g: i for i, g in enumerate(hvg_names)}
    for i, gene in enumerate(valid_genes):
        idx = gene_to_idx[gene]
        X_complete[:, idx] = adata[:, gene].X.toarray().flatten()
    
    # 5. ã€å…³é”®æ”¹è¿›ã€‘æ™ºèƒ½è¡¥å…¨ç¼ºå¤±åŸºå› 
    # ç­–ç•¥A: ä½¿ç”¨åŸºå› è¡¨è¾¾çš„å…¨å±€å‡å€¼
    global_mean = X_complete[:, [gene_to_idx[g] for g in valid_genes]].mean()
    
    # ç­–ç•¥B: ä½¿ç”¨ç»†èƒç‰¹å®šçš„ç¼©æ”¾å› å­ï¼ˆè€ƒè™‘æ–‡åº“å¤§å°ï¼‰
    cell_totals = X_complete.sum(axis=1, keepdims=True)
    median_total = np.median(cell_totals[cell_totals > 0])
    
    for gene in missing_genes:
        idx = gene_to_idx[gene]
        # ä¸ºæ¯ä¸ªç»†èƒä¼°è®¡ä¸€ä¸ªå°çš„éé›¶å€¼ï¼Œä¸æ–‡åº“å¤§å°æˆæ¯”ä¾‹
        # è€Œä¸æ˜¯å…¨éƒ¨å¡«0
        X_complete[:, idx] = (cell_totals / median_total).flatten() * global_mean * 0.1
    
    # 6. åˆ›å»ºæ–°çš„AnnDataå¯¹è±¡
    adata_complete = ad.AnnData(X=X_complete)
    adata_complete.var_names = hvg_names
    adata_complete.obs = adata.obs.copy()
    
    adata_complete.write_h5ad(data_out)
    print(f"ä¿å­˜åˆ°: {data_out}")
    print(f"è¡¥å…¨ç­–ç•¥: ä½¿ç”¨å…¨å±€å‡å€¼çš„10%ä½œä¸ºç¼ºå¤±åŸºå› çš„ä¼°è®¡å€¼")
```

#### 4.2 å¤šç§è¡¥å…¨ç­–ç•¥å¯¹æ¯”å®éªŒ

```python
# ç­–ç•¥1: çº¯é›¶è¡¥å…¨ (baseline)
fill_strategy = "zero"

# ç­–ç•¥2: å…¨å±€å‡å€¼çš„æ¯”ä¾‹
fill_strategy = "scaled_mean"

# ç­–ç•¥3: KNNæ’è¡¥ (ä½¿ç”¨å·²æœ‰åŸºå› é¢„æµ‹ç¼ºå¤±åŸºå› )
from sklearn.impute import KNNImputer
imputer = KNNImputer(n_neighbors=5)
X_complete = imputer.fit_transform(X_with_missing)

# ç­–ç•¥4: ä½¿ç”¨é¢„è®­ç»ƒçš„åŸºå› è¡¨è¾¾æ¨¡å‹ (å¦‚scVI)
# éœ€è¦å¤§é‡è®¡ç®—èµ„æº
```

### é¢„æœŸæ•ˆæœ
- **å‡†ç¡®æ€§**: ğŸŸ¡ ä¸­ç­‰ (æ¯”é›¶è¡¥å…¨å¥½ï¼Œä½†ä»æ˜¯ä¼°è®¡)
- **æ³›åŒ–æ€§**: ğŸŸ¢ é«˜ (å¯ç”¨äºä¸åŒæ•°æ®é›†)
- **å®æ–½éš¾åº¦**: ğŸŸ¢ ç®€å•
- **æ¨èæŒ‡æ•°**: â­â­â­ (å¿«é€ŸéªŒè¯çš„å¥½é€‰æ‹©)

---

## ğŸ† æ¨èæ–¹æ¡ˆç»„åˆ

### çŸ­æœŸæ–¹æ¡ˆ (1-2å¤©å®æ–½)

#### æ–¹æ¡ˆ4å‡çº§ç‰ˆ + æ–¹æ¡ˆ1ä½œä¸ºå¯¹ç…§
1. **ä¸»è¦æ–¹æ¡ˆ**: å®æ–½å¢å¼ºçš„é›¶è¡¥å…¨ç­–ç•¥
   - ä½¿ç”¨scaled_meanè¡¥å…¨
   - å¿«é€ŸéªŒè¯æ¨¡å‹åœ¨æ–°æ•°æ®ä¸Šçš„æ€§èƒ½

2. **å¯¹ç…§å®éªŒ**: åŒæ—¶è¿è¡Œçº¯é›¶è¡¥å…¨å’Œäº¤é›†åŸºå› æ–¹æ¡ˆ
   - å¯¹æ¯”ä¸‰ç§æ–¹æ³•çš„æ€§èƒ½å·®å¼‚
   - é‡åŒ–ç¼ºå¤±åŸºå› çš„å½±å“

### ä¸­æœŸæ–¹æ¡ˆ (1å‘¨å®æ–½)

#### æ–¹æ¡ˆ2: LoRAå¾®è°ƒ (å¦‚æœæœ‰æ ‡æ³¨æ•°æ®)
1. ä½¿ç”¨å¢å¼ºé›¶è¡¥å…¨çš„æ•°æ®
2. è¿›è¡ŒLoRAå¾®è°ƒ
3. è¯„ä¼°å¾®è°ƒåæ€§èƒ½æå‡

### é•¿æœŸæ–¹æ¡ˆ (å¦‚éœ€æ³›åŒ–åˆ°æ›´å¤šæ•°æ®é›†)

#### æ–¹æ¡ˆ3: è®­ç»ƒé€šç”¨åŸºå› æ˜ å°„å™¨
1. æ”¶é›†å¤šä¸ªæ•°æ®é›†
2. è®­ç»ƒé²æ£’çš„åŸºå› æ˜ å°„æ¨¡å‹
3. æ„å»ºå¯å¤ç”¨çš„æ•°æ®é¢„å¤„ç†pipeline

## ğŸ“Š å®éªŒéªŒè¯è®¡åˆ’

### å®éªŒè®¾è®¡

```mermaid
graph TD
    A[FrangiehIzar2021æ•°æ®] --> B[æ•°æ®é¢„å¤„ç†]
    B --> C1[æ–¹æ¡ˆ1: äº¤é›†åŸºå› ]
    B --> C2[æ–¹æ¡ˆ2: LoRAå¾®è°ƒ]
    B --> C3[æ–¹æ¡ˆ4a: é›¶è¡¥å…¨]
    B --> C4[æ–¹æ¡ˆ4b: æ™ºèƒ½è¡¥å…¨]
    
    C1 --> D[STæ¨¡å‹æ¨ç†]
    C2 --> D
    C3 --> D
    C4 --> D
    
    D --> E[Cell-Evalè¯„ä¼°]
    E --> F[å¯¹æ¯”åˆ†æ]
```

### è¯„ä¼°æŒ‡æ ‡

1. **ä¸»è¦æŒ‡æ ‡** (cell-evalè¾“å‡º):
   - `pearson_delta`: æ‰°åŠ¨æ•ˆåº”ç›¸å…³æ€§ (æœ€é‡è¦)
   - `mse`: é¢„æµ‹è¯¯å·®
   - `overlap_at_N`: TopåŸºå› é‡å åº¦

2. **è¾…åŠ©æŒ‡æ ‡**:
   - æ¨ç†æ—¶é—´
   - å†…å­˜å ç”¨
   - ç¼ºå¤±åŸºå› æ¯”ä¾‹çš„å½±å“

### é¢„æœŸç»“æœ

| æ–¹æ¡ˆ                | Pearson Delta | MSE | å®æ–½éš¾åº¦ | ç»¼åˆè¯„åˆ† |
| ------------------- | ------------- | --- | -------- | -------- |
| çº¯é›¶è¡¥å…¨ (baseline) | 0.4-0.5       | é«˜  | â­        | â­â­       |
| äº¤é›†åŸºå›             | 0.5-0.6       | ä¸­  | â­â­       | â­â­â­      |
| æ™ºèƒ½è¡¥å…¨            | 0.6-0.7       | ä¸­  | â­â­       | â­â­â­â­     |
| LoRAå¾®è°ƒ            | 0.7-0.8       | ä½  | â­â­â­      | â­â­â­â­â­    |

## ğŸ“ å®æ–½æ­¥éª¤æ€»ç»“

### ç¬¬ä¸€é˜¶æ®µ: å¿«é€ŸéªŒè¯ (1-2å¤©)

#### Step 1: åˆ›å»ºæ”¹è¿›çš„é¢„å¤„ç†è„šæœ¬
```bash
# æ–‡ä»¶: for_state/scripts/screen_hvgs_v2.py
# å®ç°æ™ºèƒ½è¡¥å…¨ç­–ç•¥
```

#### Step 2: è¿è¡Œå¯¹æ¯”å®éªŒ
```bash
# å®éªŒ1: çº¯é›¶è¡¥å…¨ (å·²å®Œæˆ - run23)
# å‚è€ƒ: for_state/run__commands/testing/run23.ipynb

# å®éªŒ2: æ™ºèƒ½è¡¥å…¨
python screen_hvgs_v2.py \
  --data_in FrangiehIzar2021_RNA.h5ad \
  --data_out FI_prep_smart.h5ad \
  --model_dir /path/to/ST-Tahoe \
  --fill_strategy scaled_mean

state tx infer \
  --model-dir /path/to/ST-Tahoe \
  --checkpoint /path/to/final.ckpt \
  --adata FI_prep_smart.h5ad \
  --output FI_infer_smart.h5ad \
  --pert-col perturbation_2 \
  --control-pert Control

# å®éªŒ3: äº¤é›†åŸºå› 
python screen_hvgs_intersection.py \
  --data_in FrangiehIzar2021_RNA.h5ad \
  --data_out FI_prep_intersect.h5ad \
  --model_dir /path/to/ST-Tahoe

# è¯„ä¼°å’Œå¯¹æ¯”
cell-eval run -ap FI_infer_*.h5ad -ar FI_prep.h5ad -o results/
```

#### Step 3: åˆ†æç»“æœ
```python
import pandas as pd

# è¯»å–å„å®éªŒç»“æœ
results_zero = pd.read_csv('results_zero/agg_results.csv')
results_smart = pd.read_csv('results_smart/agg_results.csv')
results_intersect = pd.read_csv('results_intersect/agg_results.csv')

# å¯¹æ¯”pearson_delta
comparison = pd.DataFrame({
    'Method': ['Zero Fill', 'Smart Fill', 'Intersection'],
    'Pearson Delta': [
        results_zero[results_zero.metric=='pearson_delta']['mean'].values[0],
        results_smart[results_smart.metric=='pearson_delta']['mean'].values[0],
        results_intersect[results_intersect.metric=='pearson_delta']['mean'].values[0]
    ]
})
print(comparison)
```

### ç¬¬äºŒé˜¶æ®µ: LoRAå¾®è°ƒ (å¦‚æœæ•°æ®è´¨é‡å¥½)

#### Step 4: å‡†å¤‡å¾®è°ƒæ•°æ®
```bash
# ä½¿ç”¨æœ€ä½³çš„é¢„å¤„ç†æ–¹æ³•ï¼ˆæ ¹æ®ç¬¬ä¸€é˜¶æ®µç»“æœé€‰æ‹©ï¼‰
python screen_hvgs_v2.py \
  --data_in FrangiehIzar2021_RNA.h5ad \
  --data_out FI_for_finetune.h5ad \
  --model_dir /path/to/ST-Tahoe \
  --fill_strategy [best_strategy_from_stage1]
```

#### Step 5: è¿è¡ŒLoRAå¾®è°ƒ
```bash
export CUDA_VISIBLE_DEVICES=3
python finetune_v2.py \
  --model_dir /path/to/ST-Tahoe \
  --checkpoint /path/to/final.ckpt \
  --adata FI_for_finetune.h5ad \
  --pert_col perturbation_2 \
  --control_label "Control" \
  --output_lora lora_FI.pth \
  --epochs 10 \
  --batch_size 128 \
  --lr 5e-4 \
  --lora_rank 16 \
  --use_delta_loss \
  --batch_col plate
```

#### Step 6: ä½¿ç”¨å¾®è°ƒæ¨¡å‹æ¨ç†
```bash
# éœ€è¦å®ç°æ”¯æŒLoRAçš„æ¨ç†è„šæœ¬
python infer_with_lora.py \
  --model-dir /path/to/ST-Tahoe \
  --checkpoint /path/to/final.ckpt \
  --lora_weights lora_FI.pth \
  --adata FI_for_finetune.h5ad \
  --output FI_infer_lora.h5ad
```

### ç¬¬ä¸‰é˜¶æ®µ: æ–‡æ¡£å’Œæ€»ç»“

#### Step 7: æ’°å†™æŠ€æœ¯æŠ¥å‘Š
- å„æ–¹æ¡ˆæ€§èƒ½å¯¹æ¯”
- ç¼ºå¤±åŸºå› å½±å“åˆ†æ
- æœ€ä½³å®è·µå»ºè®®

## ğŸ”¬ ç°æœ‰ä»£ç åˆ†æ

### run23å®éªŒå›é¡¾

ä» [`run23.ipynb`](../for_state/run__commands/testing/run23.ipynb) å¯ä»¥çœ‹åˆ°:

1. **æ•°æ®å¤„ç†**: ä½¿ç”¨äº† `screen_hvgs()` å‡½æ•°ï¼Œ`fill_missing=True`
   ```python
   screen_hvgs(
       data_in='FrangiehIzar2021_RNA.h5ad',
       data_out='FI_prep.h5ad',
       model_dir='/path/to/ST-Tahoe',
       fill_missing=True  # â† ä½¿ç”¨é›¶è¡¥å…¨
   )
   ```

2. **æ¨ç†æˆåŠŸ**: å¤„ç†äº†218,331ä¸ªç»†èƒ
   ```
   Input cells:         218331
   Controls simulated:  57627
   Treated simulated:   160704
   ```

3. **è¯„ä¼°å®Œæˆ**: ä½¿ç”¨minimal profileè¿›è¡Œè¯„ä¼°
   - ä½†**ç¼ºå°‘æœ€ç»ˆæ€§èƒ½æŒ‡æ ‡**ï¼éœ€è¦æŸ¥çœ‹ `agg_results.csv`

### å…³é”®é—®é¢˜
â“ run23çš„å®é™…æ€§èƒ½å¦‚ä½•ï¼Ÿ  
â“ é›¶è¡¥å…¨å¸¦æ¥çš„æ€§èƒ½æŸå¤±æœ‰å¤šå¤§ï¼Ÿ  
â“ æ˜¯å¦æœ‰ç‰¹å®šçš„æ‰°åŠ¨ç±»å‹å—å½±å“æ›´ä¸¥é‡ï¼Ÿ

## ğŸ› ï¸ éœ€è¦åˆ›å»ºçš„æ–°è„šæœ¬

### 1. `screen_hvgs_v2.py`
å¢å¼ºçš„é¢„å¤„ç†è„šæœ¬ï¼Œæ”¯æŒå¤šç§è¡¥å…¨ç­–ç•¥

### 2. `screen_hvgs_intersection.py`
åªä½¿ç”¨äº¤é›†åŸºå› çš„é¢„å¤„ç†è„šæœ¬

### 3. `infer_with_lora.py`
æ”¯æŒåŠ è½½LoRAæƒé‡çš„æ¨ç†è„šæœ¬

### 4. `analyze_gene_impact.py`
åˆ†æç¼ºå¤±åŸºå› å¯¹æ€§èƒ½çš„å½±å“

### 5. `compare_methods.py`
è‡ªåŠ¨åŒ–å¯¹æ¯”ä¸åŒæ–¹æ¡ˆçš„è„šæœ¬

## ğŸ“ˆ æˆæœ¬æ”¶ç›Šåˆ†æ

| æ–¹æ¡ˆ                 | å®æ–½æ—¶é—´ | è®¡ç®—èµ„æº   | æ•°æ®éœ€æ±‚     | é¢„æœŸæå‡ | ROI  |
| -------------------- | -------- | ---------- | ------------ | -------- | ---- |
| æ–¹æ¡ˆ1: äº¤é›†åŸºå›       | 0.5å¤©    | ä½         | æ—            | +10%     | é«˜   |
| æ–¹æ¡ˆ2: LoRAå¾®è°ƒ      | 1å¤©      | ä¸­ (éœ€GPU) | éœ€æ ‡æ³¨       | +30%     | é«˜   |
| æ–¹æ¡ˆ3: Embeddingæ˜ å°„ | 5å¤©      | é«˜         | éœ€å¤§é‡æ— æ ‡æ³¨ | +20%     | ä½   |
| æ–¹æ¡ˆ4: æ™ºèƒ½è¡¥å…¨      | 0.5å¤©    | ä½         | æ—            | +15%     | å¾ˆé«˜ |

## ğŸ“ ç”Ÿç‰©å­¦è€ƒè™‘

### ç¼ºå¤±åŸºå› çš„ç”Ÿç‰©å­¦æ„ä¹‰

1. **åŸºå› åŠŸèƒ½ç›¸å…³æ€§**:
   - æŸäº›åŸºå› å¯èƒ½åœ¨ç‰¹å®šæ‰°åŠ¨ä¸‹ä¸è¡¨è¾¾ï¼ˆçœŸå®çš„é›¶ï¼‰
   - ä½†æ¨¡å‹è®­ç»ƒæ—¶çš„é›¶å€¼ä¸»è¦æ¥è‡ªæŠ€æœ¯å™ªéŸ³

2. **åŸºå› å…±è¡¨è¾¾ç½‘ç»œ**:
   - å¯ä»¥åˆ©ç”¨åŸºå› é—´ç›¸å…³æ€§è¿›è¡Œimputation
   - ä½†éœ€è¦å¤§é‡ç»†èƒæ¥ä¼°è®¡ç›¸å…³æ€§çŸ©é˜µ

3. **æ‰°åŠ¨ç‰¹å¼‚æ€§**:
   - CRISPRæ•²é™¤ vs è¯ç‰©å¤„ç† çš„è¡¨è¾¾æ¨¡å¼ä¸åŒ
   - å¯èƒ½éœ€è¦é’ˆå¯¹æ‰°åŠ¨ç±»å‹è°ƒæ•´ç­–ç•¥

## ğŸš€ å¿«é€Ÿå¼€å§‹æ£€æŸ¥æ¸…å•

- [ ] ç¡®è®¤run23çš„å®é™…æ€§èƒ½æŒ‡æ ‡
- [ ] åˆ†æç¼ºå¤±åŸºå› çš„æ¯”ä¾‹å’Œåˆ†å¸ƒ
- [ ] å®æ–½æ–¹æ¡ˆ4 (æ™ºèƒ½è¡¥å…¨) ä½œä¸ºé¦–é€‰
- [ ] è¿è¡Œæ–¹æ¡ˆ1 (äº¤é›†åŸºå› ) ä½œä¸ºå¯¹ç…§
- [ ] å¦‚æœæ€§èƒ½ä¸ä½³ï¼Œè€ƒè™‘æ–¹æ¡ˆ2 (LoRAå¾®è°ƒ)
- [ ] è®°å½•æ‰€æœ‰å®éªŒçš„è¶…å‚æ•°å’Œç»“æœ
- [ ] æ’°å†™æŠ€æœ¯æŠ¥å‘Šå’Œæœ€ä½³å®è·µæ–‡æ¡£

## ğŸ“š å‚è€ƒèµ„æº

### ç›¸å…³æ–‡ä»¶
- æ¨¡å‹æ¶æ„: [`src/state/tx/models/state_transition.py`](../src/state/tx/models/state_transition.py)
- é¢„å¤„ç†è„šæœ¬: [`for_state/scripts/screen_hvgs.py`](../for_state/scripts/screen_hvgs.py)
- LoRAå¾®è°ƒ: [`for_state/scripts/finetune_v2.py`](../for_state/scripts/finetune_v2.py)
- æ¨ç†CLI: [`src/state/_cli/_tx/_infer.py`](../src/state/_cli/_tx/_infer.py)

### å®éªŒè®°å½•
- run20: MMDå¯¹é½å®éªŒ ([`run20.ipynb`](../for_state/run__commands/succeeded/run20.ipynb))
- run21: åŸºçº¿å¯¹ç…§å®éªŒ ([`run21.ipynb`](../for_state/run__commands/succeeded/run21.ipynb))
- run23: å½“å‰çš„æ³›åŒ–æµ‹è¯• ([`run23.ipynb`](../for_state/run__commands/testing/run23.ipynb))

## ğŸ”„ åç»­è¿­ä»£æ–¹å‘

### çŸ­æœŸä¼˜åŒ–
1. å®ç°è‡ªé€‚åº”è¡¥å…¨ï¼šæ ¹æ®åŸºå› è¡¨è¾¾åˆ†å¸ƒåŠ¨æ€é€‰æ‹©ç­–ç•¥
2. é›†æˆå¤šç§è¡¥å…¨æ–¹æ³•çš„ensemble
3. å¼€å‘å¯è§†åŒ–å·¥å…·åˆ†æç¼ºå¤±åŸºå› çš„å½±å“

### é•¿æœŸç ”ç©¶
1. å¼€å‘åŸºå› ç»´åº¦æ— å…³çš„æ¨¡å‹æ¶æ„
2. æ¢ç´¢zero-shot transfer learningæ–¹æ³•
3. æ„å»ºè·¨æ•°æ®é›†çš„åŸºå› è¡¨è¾¾æ ‡å‡†åŒ–æ–¹æ³•

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¥æœŸ**: 2025-12-23  
**æœ€åæ›´æ–°**: 2025-12-23  
**ä½œè€…**: AI Architect  
**é¡¹ç›®**: STæ¨¡å‹æ³›åŒ–èƒ½åŠ›ç ”ç©¶
